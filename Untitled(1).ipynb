{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ef55e0-ee9d-422f-bbf5-fcdff8c0c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.4.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.3/515.3 kB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m134.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, hf-xet, fsspec, huggingface_hub, tokenizers, accelerate, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-1.8.1 fsspec-2025.7.0 hf-xet-1.1.5 huggingface_hub-0.33.4 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.2 tqdm-4.67.1 transformers-4.53.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers huggingface_hub accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753bc4ca-7e27-4915-89f5-7e523b960141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd0077163e549bda8b5cffbcdb6b26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2cce2d25b347c0b9798a0dcd5ca78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6ab2b1cff742c8bdfb5643c5321b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b62410646bc4c4fa00907647503ca99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d18c784de94e68a889010c6bf8828d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10413ba12ab4a228a91a2d60de92824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742596fee4f74d9382ee4648cf83c032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9958fd682cbe441a8b000e13cefeae82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af640be5fbe54563b017ab6c930e528f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3976f888ae1f48a8846526e1a17ed159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa89d2bcf2744a3a4490fd5bbd3f9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6919b6fcbec64ac88b81d41500f365eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314dbb867c9b4dc5b33b8a322dc18803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c398cff50ac84cf7a9f2686f9672366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b49758c12c944ee8fe057d88f21b799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12b9dd4d8245f3b884b3ebdadbc6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's see. So the problem is about A, B, and C working together to complete a piece of work. We need to figure out how much money C should get for his help. The total payment is Rs. 3200, and we have to divide that among A, B, and C based on their contributions. Let me try to break this down step by step.\n",
      "\n",
      "First, let's understand the work rates of A and B. A can finish the work in 6 days, so his work rate is 1/6 of the work per day. Similarly, B can finish it in 8 days, so his work rate is 1/8 per day. When they work together, their combined work rate would be 1/6 + 1/8. Let me calculate that:\n",
      "\n",
      "1/6 + 1/8. To add these, find a common denominator, which is 24. So, 4/24 + 3/24 = 7/24. So together, A and B can do 7/24 of the work in one day.\n",
      "\n",
      "But the problem says that with the help of C, they completed the work in 3 days. That means all three working together finished the job in 3 days. Let's denote C's work rate as 1/x per day, where x is the number of days C would take alone. So, the combined work rate of A, B, and C is 1/6 + 1/8 + 1/x.\n",
      "\n",
      "Since they completed the work in 3 days, their combined work rate multiplied by 3 should equal 1 (the whole work). So:\n",
      "\n",
      "(1/6 + 1/8 + 1/x) * 3 = 1\n",
      "\n",
      "Let me solve for 1/x first. Let's compute 1/6 + 1/8:\n",
      "\n",
      "As before, 1/6 is 4/24 and 1/8 is 3/24, so together they are 7/24. So:\n",
      "\n",
      "(7/24 + 1/x) * 3 = 1\n",
      "\n",
      "Divide both sides by 3:\n",
      "\n",
      "7/24 + 1/x = 1/3\n",
      "\n",
      "Subtract 7/24 from both sides:\n",
      "\n",
      "1/x = 1/3 - 7/24\n",
      "\n",
      "Convert 1/3 to 8/24:\n",
      "\n",
      "1/x = 8/24 - 7/24 = 1/24\n",
      "\n",
      "So, 1/x = 1/24, which means x = 24. Therefore, C's work rate is 1/24 per day. So, C alone can finish the work in 24 days.\n",
      "\n",
      "Now, we need to find out how much work each person did. The total work is 1 unit. Let's calculate the work done by each in 3 days.\n",
      "\n",
      "A's work in 3 days: 3 * (1/6) = 3/6 = 1/2\n",
      "\n",
      "B's work in 3 days: 3 * (1/8) = 3/8\n",
      "\n",
      "C's work in 3 days: 3 * (1/24) = 3/24 = 1/8\n",
      "\n",
      "Let me check if these add up to 1:\n",
      "\n",
      "1/2 + 3/8 + 1/8 = (4/8 + 3/8 + 1/8) = 8/8 = 1. Perfect, that adds up.\n",
      "\n",
      "Now, the total payment is Rs. 3200, so we need to divide this amount according to the work done by each person.\n",
      "\n",
      "First, let's find the ratio of their work. The work done by A is 1/2, by B is 3/8, and by C is 1/8. To make it easier, let's convert these fractions to have the same denominator. The denominators are 2, 8, 8. The least common denominator is 8.\n",
      "\n",
      "Convert A's work: 1/2 = 4/8\n",
      "\n",
      "B's work: 3/8\n",
      "\n",
      "C's work: 1/8\n",
      "\n",
      "So the ratio of their work is 4:3:1.\n",
      "\n",
      "Therefore, the total parts are 4 + 3 + 1 = 8 parts.\n",
      "\n",
      "The total payment is Rs. 3200, so each part is worth 3200 / 8 = 400.\n",
      "\n",
      "Therefore, C's share is 1 part, which is 400 * 1 = 400.\n",
      "\n",
      "Wait, that seems straightforward. Let me verify again.\n",
      "\n",
      "Alternatively, we can calculate each person's payment based on their work done.\n",
      "\n",
      "A did 1/2 of the work, so he should get (1/2)*3200 = 1600\n",
      "\n",
      "B did 3/8, so (3/8)*3200 = 1200\n",
      "\n",
      "C did 1/8, so (1/8)*3200 = 400\n",
      "\n",
      "Adding these up: 1600 + 1200 + 400 = 3200. That's correct.\n",
      "\n",
      "So yes, C should get Rs. 400.\n",
      "\n",
      "Hmm, but let me check once more to be sure. Sometimes when there are multiple steps, it's easy to make a mistake.\n",
      "\n",
      "First, work rates:\n",
      "\n",
      "A: 1/6 per day\n",
      "\n",
      "B: 1/8 per day\n",
      "\n",
      "Combined without C: 7/24 per day\n",
      "\n",
      "With C, they finish in 3 days, so their combined rate is 1/3 per day.\n",
      "\n",
      "So, 7/24 + C's rate = 1/3\n",
      "\n",
      "C's rate = 1/3 - 7/24 = 8/24 - 7/24 = 1/24 per day. So, C's rate is 1/24 per day.\n",
      "\n",
      "Work done by C in 3 days: 3*(1/24) = 1/8. So, 1/8 of the work.\n",
      "\n",
      "Total work is 1, so C's share is 1/8 of 3200 = 400. Yep, that's correct.\n",
      "\n",
      "Alternatively, using ratios:\n",
      "\n",
      "Work done by A: 1/2, B: 3/8, C: 1/8. So the ratio is 4:3:1 as before.\n",
      "\n",
      "Total parts 8, so 3200/8 = 400 per part. C has 1 part, so 400.\n",
      "\n",
      "Yes, that's consistent. So the answer should be Rs. 400.\n",
      "\n",
      "I think that's solid. I can't see any mistakes in the calculations. So C should be paid Rs. 400.\n",
      "</think>\n",
      "content: To determine how much C should be paid, we first calculate the work rates of A, B, and C.\n",
      "\n",
      "- A's work rate: $ \\frac{1}{6} $ of the work per day\n",
      "- B's work rate: $ \\frac{1}{8} $ of the work per day\n",
      "- Combined work rate of A and B: $ \\frac{1}{6} + \\frac{1}{8} = \\frac{7}{24} $ of the work per day\n",
      "\n",
      "With C's help, the combined work rate of A, B, and C is $ \\frac{1}{3} $ of the work per day (since they completed the work in 3 days). Let C's work rate be $ \\frac{1}{x} $ per day. Then:\n",
      "\n",
      "$$\n",
      "\\frac{7}{24} + \\frac{1}{x} = \\frac{1}{3}\n",
      "$$\n",
      "\n",
      "Solving for $ \\frac{1}{x} $:\n",
      "\n",
      "$$\n",
      "\\frac{1}{x} = \\frac{1}{3} - \\frac{7}{24} = \\frac{8}{24} - \\frac{7}{24} = \\frac{1}{24}\n",
      "$$\n",
      "\n",
      "Thus, C's work rate is $ \\frac{1}{24} $ per day. In 3 days, C completes:\n",
      "\n",
      "$$\n",
      "3 \\times \\frac{1}{24} = \\frac{1}{8} \\text{ of the work}\n",
      "$$\n",
      "\n",
      "The total work is 1 unit. The work done by A, B, and C in 3 days is:\n",
      "\n",
      "- A: $ 3 \\times \\frac{1}{6} = \\frac{1}{2} $\n",
      "- B: $ 3 \\times \\frac{1}{8} = \\frac{3}{8} $\n",
      "- C: $ \\frac{1}{8} $\n",
      "\n",
      "The ratio of their work contributions is $ \\frac{1}{2} : \\frac{3}{8} : \\frac{1}{8} = 4 : 3 : 1 $. The total parts are 8, so each part is worth $ \\frac{3200}{8} = 400 $. Therefore, C's share is:\n",
      "\n",
      "$$\n",
      "1 \\times 400 = 400\n",
      "$$\n",
      "\n",
      "Thus, C should be paid Rs. 400.\n",
      "\n",
      "$$\n",
      "\\boxed{400}\n",
      "$$\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"prithivMLmods/Omega-Qwen3-Atom-8B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"A alone can do a piece of work in 6 days and B alone in 8 days. A and B undertook to do it for Rs. 3200. With the help of C, they completed the work in 3 days. How much is to be paid to C?\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54cdae-4d83-434b-bd30-62e86de7bfb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
